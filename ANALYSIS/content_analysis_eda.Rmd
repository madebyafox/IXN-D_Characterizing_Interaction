---
title: "IXN 1 â€” Exploratory Data Analysis"
author: "ANONYMIZED"
date: "2023-09-08"
output:
  html_document:
    theme: flatly
    code_folding: hide
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    toc_depth: 4
  pdf_document:
    toc: yes
    toc_depth: '4'
always_allow_html: yes
font-family: DejaVu Sans
mainfont: DejaVu Sans
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#UTILITIES
library(Hmisc) # %nin% operator
library(tidyverse) #all the things
library(summarytools) #data quality
library(jtools) #Social Science regression utilities
library(lubridate) #dealing with dates

#VIZ
library(kableExtra) #printing tables
library(ggformula) #regression syntax viz
library(vcd) #mosaic plots
library(vcdExtra) #mosaic plot helpers
library(ggstatsplot) #dummies

#MODELLING
library(easystats) #modelling helpers
library(see)
library(sjPlot)
library(lme4)
library(lmerTest) #for CIs in glmer

options(readr.show_col_types = FALSE) #don't show coltypes on read_csv

```

```{r IMPORT}  

#IMPORT (wrangled) data 
df_raw <- read_csv("data/CLEAN_UtterancesForAnalysis.csv") 

#WRANGLE into DF of coded utterances 
#NOT unique utterances, 1 obs for each utterance+detail-code
df_coded <- df_raw %>% 
  #rename and factorize cols
  mutate(
    #UNIQUE IDS
    sid = factor(SID), #unique ID for utterance+detail-code
    pid = factor(PID, levels = c( #define level order so happiness first
      #HAPPINESS-FIRST    
      "bjs827ee1u", "3r2sh20ei", "4728sjuiz","7ACC0B75","92ghd48xe","iurmer289", "s294hoei",
      #SPACE-FIRST    
      "j2719eertu2","lkin27js09b","li832lin23","7382kwtue","E1D39056","8v892iige")),   
    #create unique ID for utterances
    uid = factor(as.numeric(factor(paste(pid,factor(Utterance))))), #construct a unique ID for utterances
    #recode lower case and order based on true task order
    TASK = factor(recode(Condition, "Static"="static", "Interactive"="ixn" )),
    TASK = factor(TASK, levels = c("static", "ixn")), #reorder factor levels
    #rename Notebook as DATASET
    DATASET = factor(recode(Notebook, "Happiness"="happiness", "Space"="space")),
    #create temp dataset order var
    data_order = factor(paste(TASK,"_",DATASET)), #create an order var 
    data_order = recode(data_order, "ixn _ happiness"="space-first",
                                    "ixn _ space"="happiness-first",
                                    "static _ happiness"="happiness-first",
                                    "static _ space"="space-first"),
    utterance = Utterance,
    reps_group = factor(`group`),
    reps_all = factor(`All representations`),
    #rename flags
    flag_story = `Flag Storytelling`,
    flag_correction = `Flag Correction`,
    flag_simultaneous = `Flag Simultaneous Characterization`,
    #recode and order TOP LEVEL CODES 
    code_topic = factor(Highlevel),
    code_topic = recode(code_topic, "ANALYSIS PROCESS" = "PROCESS"),
    code_topic = factor(code_topic, levels = c("PROCESS","DATASET","VARIABLE","RELATIONSHIP")),
    code_datatype = factor(`Data Type`),
    code_detail = factor(`Utterance Type`),
    timestamp = adj_timestamp,
    ixn = factor(interaction_used), #was interaction used?
    PNUM = factor(PNUM,levels = c("P6", "P9", "P10", "P2", "P4", "P12","P13", 
                                   "P5", "P7", "P8", "P3", "P1","P11")),
    
    ) %>% 
  select(sid,pid,PNUM,uid,TASK,DATASET,timestamp,ixn,code_topic,code_detail,code_datatype,
         flag_story, flag_correction, flag_simultaneous, utterance, reps_group, reps_all, data_order) %>% 
  arrange(data_order)

#REPLACE NA in logicals to FALSE  
df_coded$flag_story[is.na(df_coded$flag_story)] <- FALSE
df_coded$flag_correction[is.na(df_coded$flag_correction)] <- FALSE
df_coded$flag_simultaneous[is.na(df_coded$flag_simultaneous)] <- FALSE



#CALCULATE RELATIVE TASK TIMES
df_time <- df_coded %>% mutate(
  time = hms::as_hms(timestamp)
) %>% group_by(pid, TASK) %>% 
  # dplyr::summarise( .groups="keep",
  mutate(
    task_start = hms::as_hms(min(time)),
    task_end = hms::as_hms(max(time)),
    task_mins = round(difftime(task_end,task_start, units="mins"),1),
    task_second = task_end - task_start,
    relative_time = timestamp-task_start,
    rel_time = as.double(relative_time)
  ) %>% ungroup() %>% select(pid,PNUM, code_topic,TASK,DATASET,timestamp,task_start,relative_time,rel_time)


```

**There are `r nrow(df_coded)` rows in the `df_coded` dataset, where each row represents an utterance coding (i.e. utterance + detail code).  There are `r nlevels(df_coded$uid)` _unique_ utterances. The difference indicates utterances that were _dual-coded_ (i.e. two detail-level codes). No more than two codes were applied to a single utterance.  For the purposes of analysis, dual-coded utterances will be treated as two utterances, as they have two distinct (but lexically insepeperable) units of meaning. 

# DATA PROFILE

```{r data-profile, results="asis", warning=FALSE, message=FALSE}

df_coded%>% summarytools::dfSummary(
             plain.ascii  = FALSE,
             graph.magnif = 0.75,
             style        = "grid",
             tmp.img.dir  = "temp",
             missing.col = FALSE, 
             method = "render"
)

```


# UTTERANCES

## by TASK

```{r results='asis'}

print("BY TASK")
freq(df_coded$TASK, 
     cumul      = FALSE,
     headings   = FALSE,
     report.nas = FALSE,
     plain.ascii = FALSE) 

```

## by TASK and DATASET
```{r results="asis", message=FALSE}

#COUNT BY TASK AND DATASET
ctable(x = df_coded$TASK, 
       y = df_coded$DATASET, 
       prop = "t")  

#DF SUMMARIZED BY TASK + DATASET
df_summary <- df_coded %>% 
  group_by(TASK,DATASET) %>% 
  dplyr::summarise(
    c = n()
  )

#STACKED BAR BY TASK
ggplot(df_summary, aes(x = TASK, y=c, fill= DATASET)) + 
  geom_col() + 
  geom_text(aes(label=c), size = 3, hjust = 0.5, vjust = 1.5, position = "stack") + 
  # scale_fill_brewer(type="qual", palette = 4) +
  labs( title = "Utterances by TASK and DATASET",
        subtitle = "More utterances in STATIC; more utterances in HAPPINESS",
        x= "TASK", y = "count") + theme_minimal() 
# + theme(legend.position = "blank")

```

## by PARTICIPANT
```{r results="asis", message=FALSE}

#COUNT BY PARTICIPANT AND TASK
ctable(x = df_coded$PNUM, 
       y = df_coded$TASK, 
       prop = "r")  

#UTTERANCES by PARTICPANT facet TASK
gf_bar( PNUM ~., fill = ~ DATASET, data = df_coded) %>% 
  gf_facet_grid(.~TASK) + 
  labs(
    title = "Utterances by Participant, Dataset and Task",
    subtitle = "",
    x = "number of coded utterances",
    y = "participant",
    fill = "DATASET"
  )

```


## by TIME

```{r}

#DOTPLOT
ggplot(df_time, aes(x=rel_time, y = PNUM)) + 
  geom_point(alpha=0.5, size=3) +
  facet_grid(df_time$TASK) +
  scale_color_brewer(type="qual", palette = 3) +
  theme_minimal() + labs(
    title = "Participant Utterances over timecourse of Task",
    x= "timecourse of task (seconds)", y = "Participant",
    color = "Topic"
  ) 


#HISTOGRAMS BY TASK
ggplot(df_time, aes(x = rel_time)) + 
  geom_histogram(binwidth = 30,aes(y=..density..)) + 
  geom_density()+
  facet_grid(df_time$TASK) +
  theme_minimal() + labs(
    title = "Participant Utterances over timecourse of Task",
    x= "timecourse of task (seconds)", y = "frequency of utterances",
  ) + theme_minimal() + theme(legend.position = "blank")


```

# TOP-CODE

## by TASK
```{r results='asis', message=FALSE}

#COUNT BY TASK
ctable(x = df_coded$code_topic, 
       y = df_coded$TASK, 
       prop = "r")  

#DF SUMMARIZED BY TASK + DATASET
df_summary <- df_coded %>% 
  group_by(code_topic, TASK) %>% 
  dplyr::summarise(
    c = n()
  )

#STACKED BAR BY TASK
ggplot(df_summary, aes(x = TASK, y=c, fill= fct_rev(code_topic))) + 
  geom_col() + 
  geom_text(aes(label=c), size = 3, hjust = 0.5, vjust = 1.5, position = "stack") + 
  scale_fill_brewer(type="qual", palette = 3) +
  labs( title = "TOPICS by TASK",
        subtitle = "",
        x= "TASK", y = "count", fill="TOPIC") + theme_minimal() 
# + theme(legend.position = "blank")
```

##  by TASK and DATASET
```{r results="asis", message=FALSE}

#COUNT BY TASK AND DATASET
table(df_coded$code_topic, df_coded$TASK, df_coded$DATASET) %>% addmargins()

#DF SUMMARIZED BY TASK + DATASET
df_summary <- df_coded %>%
  group_by(code_topic, TASK,DATASET) %>%
  dplyr::summarise(
    c = n()
  )

#STACKED BAR BY TASK FACET DATASET
ggplot(df_summary, aes(x = TASK, y=c, fill= fct_rev(code_topic))) +
  facet_wrap(df_summary$DATASET) +
  geom_col() +
  geom_text(aes(label=c), size = 3, hjust = 0.5, vjust = 1.5, position = "stack") +
  scale_fill_brewer(type="qual", palette = 3) +
  labs( title = "TOPICS by TASK and DATASET",
        subtitle = "",
        x= "TASK", y = "count", fill="TOPIC") + theme_minimal()
# + theme(legend.position = "blank")

```



## by PARTICIPANT
```{r results="asis", message=FALSE}

#COUNT BY PARTICIPANT 
ctable(x = df_coded$PNUM, 
       y = df_coded$code_topic, 
       prop = "r")  

#TOPICS by PARTICPANT facet TASK
gf_bar( PNUM ~., fill = ~ fct_rev(code_topic), data = df_coded) %>% 
  gf_facet_grid(.~TASK) + 
  scale_fill_brewer(type="qual", palette = 3) +
  labs(
    title = "Utterances by Participant, Dataset and Task",
    subtitle = "",
    x = "number of coded utterances",
    y = "participant",
    fill = "DATASET"
  )


# #TOPICS by PARTICPANT facet TASK
# gf_bar( PNUM ~., fill = ~ fct_rev(code_topic), data = df_coded) %>% 
#   gf_facet_grid(DATASET~TASK) + 
#   scale_fill_brewer(type="qual", palette = 3) +
#   labs(
#     title = "Utterances by Participant, Dataset and Task",
#     subtitle = "",
#     x = "number of coded utterances",
#     y = "participant",
#     fill = "DATASET"
#   )
```
## by TIME

```{r}

#DOTPLOT
ggplot(df_time, aes(x=rel_time, y = PNUM, color=fct_rev(code_topic))) + 
  geom_point(alpha=0.5, size=3) +
  facet_grid(df_time$TASK) +
  scale_color_brewer(type="qual", palette = 3) +
  theme_minimal() + labs(
    title = "Participant Utterances over timecourse of Task",
    x= "timecourse of task (seconds)", y = "Participant",
    color = "Topic"
  ) 


#HISTOGRAMS BY TASK
ggplot(df_time, aes(x = rel_time)) + 
  geom_histogram(binwidth = 30,aes(y=..density.., fill = fct_rev(code_topic), color = fct_rev(code_topic))) + 
  geom_density()+
  facet_grid(df_time$code_topic ~ df_time$TASK) +
  scale_fill_brewer(type="qual", palette = 3) +
  scale_color_brewer(type="qual", palette = 3) +
  theme_minimal() + labs(
    title = "Participant Utterances over timecourse of Task",
    x= "timecourse of task (seconds)", y = "frequency of utterances",
    fill = "Topic"
  ) + theme_minimal() + theme(legend.position = "blank")


```






# REPRESENTATIONS

How many representations were created?
```{r results='asis'}

print("BY TASK")
freq(df_coded$reps_all,
     cumul      = FALSE,
     headings   = FALSE,
     report.nas = FALSE,
     plain.ascii = FALSE)

```




# MODELLING

```{r VIZ-B4-MODEL, message=FALSE}

#DEFINE DATAFRAME
df <- df_coded %>% select(pid, uid, TASK, DATASET) 
  
#MOSAIC PLOT
mosaic(formula = ~DATASET + TASK, 
       data = df,
       main = "Proportion of Utterances by TASK and DATASET", 
       sub = "u = 734 utterance-codes",
       labeling = labeling_values,
       labeling_args = list(set_varnames = c(graph = "TASK",
                            datset = "DATASET")))




```


## UTTERANCES

*How much variance in number of utterances is explained DATASET, TASK and PARTICIPANT?*

### OLS Mixed Effects Models
```{r OLS-MIXED-EFFECTS-MODELS}

#DEFINE DATAFRAME
df <- df_coded %>% group_by(pid, DATASET, TASK) %>% 
  dplyr::summarise( .groups = "keep",
    n_utterances = n()
  )

#NUMBER UTTERANCES predicted by DATASET + TASK | participatnt--> MIXED LINEAR REGRESSION
print("LMER, UTTERANCES ~ DATASET + TASK")
mm1 <- lmer(n_utterances ~ DATASET + TASK+ (1|pid), data = df)
paste("Model")
summ(mm1)
paste("Partition Variance")
anova(mm1)
paste("Confidence Interval on Parameter Estimates")
confint(mm1)
report(mm1) #sanity check
plot_model(mm1,  show.intercept = TRUE)
check_model(mm1)


#NUMBER UTTERANCES predicted by DATASET * TASK  | participatnt--> MIXED LINEAR REGRESSION
print("LMER, UTTERANCES ~ DATASET X TASK")
mm2 <- lmer(n_utterances ~ DATASET * TASK + (1|pid), data = df)
paste("Model")
summ(mm2)
paste("Partition Variance")
anova(mm2)
paste("Confidence Interval on Parameter Estimates")
confint(mm2)
report(mm2) #sanity check
plot_model(mm2,  show.intercept = TRUE)
check_model(mm2)
```

### POISSON Mixed Effects Models
```{r POISSON-MIXED-EFFECTS-MODELS}

# 
# #NUMBER UTTERANCES predicted by TASK + DATASET  | participatnt--> POISSON MIXED LINEAR REGRESSION
# print("POISSON-MER, UTTERANCES ~ DATASET + TASK")
# pmm1 <- glmer(n_utterances ~ TASK + DATASET + (1|pid), data = df, family = "poisson")
# paste("Model")
# summ(pmm1)
# paste("Partition Variance")
# anova(pmm1)
# paste("Confidence Interval on Parameter Estimates")
# confint(pmm1)
# report(pmm1) #sanity check
# plot_model(pmm1,  show.intercept = TRUE)
# check_model(pmm1)
# 
# #NUMBER UTTERANCES predicted by TASK X DATASET  | participatnt--> POISSON MIXED LINEAR REGRESSION
# print("POISSON-MER, UTTERANCES ~ DATASET X TASK")
# pmm2 <- glmer(n_utterances ~ TASK * DATASET + (1|pid), data = df, family = "poisson")
# paste("Model")
# summ(pmm2)
# paste("Partition Variance")
# anova(pmm2)
# paste("Confidence Interval on Parameter Estimates")
# confint(pmm2)
# report(pmm2) #sanity check
# plot_model(pmm2,  show.intercept = TRUE)
# check_model(pmm2)

```







